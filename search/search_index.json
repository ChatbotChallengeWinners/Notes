{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"index.html","title":"Home","text":"<p>LangChain Setup</p>"},{"location":"LangChain%20info.html","title":"LangChain info","text":""},{"location":"LangChain%20info.html#general","title":"General","text":""},{"location":"LangChain%20info.html#quickstart-tutorial","title":"Quickstart Tutorial","text":"<ul> <li>Setting up LangChain with local LLM</li> <li>Create embeddings from a website</li> </ul> <p>Note</p> <p>They use llama2 in this tutorial, but you can use any other model instead  (e.g. llama3.2, deepseek-r1)</p> <p>Docker container: DockerHub: LangChain</p>"},{"location":"LangChain%20info.html#embedding-databases","title":"Embedding Databases","text":""},{"location":"LangChain%20info.html#chromadb","title":"ChromaDB","text":"<ul> <li>vector database for embedding data (e.g. from CSV file or website scrape)</li> <li>saves embeddings as SQLite DB</li> </ul>"},{"location":"LangChain%20info.html#gui","title":"GUI","text":""},{"location":"LangChain%20info.html#steamlit","title":"Steamlit","text":"<ul> <li>Easy GUI in python (runs in browser)</li> <li>Has UI elements for LLM interaction (Example)</li> </ul>"},{"location":"LangChain%20info.html#setup-tutorials-oldother","title":"Setup Tutorials (old/other)","text":"<ul> <li>Build and Deploy a LangChain-Powered Chat App with Docker and Streamlit</li> <li>Self-hosting LangSmith with Docker</li> <li>Langchain + Docker + Neo4j + Ollama stack</li> </ul>"}]}