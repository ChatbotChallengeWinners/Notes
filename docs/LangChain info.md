
## General
### [Quickstart Tutorial](https://python.langchain.com/v0.1/docs/get_started/quickstart/)
- Setting up LangChain with local LLM
- Create embeddings from a website

> [!note]
> They use llama2 in this tutorial, but you can use any other model instead 
> (e.g. llama3.2, deepseek-r1)

Docker container: [DockerHub: LangChain](https://hub.docker.com/r/langchain/langchain)

## Embedding Databases
### [ChromaDB](https://python.langchain.com/docs/integrations/vectorstores/chroma/)
- vector database for embedding data (e.g. from CSV file or website scrape)
- saves embeddings as SQLite DB
## GUI
### [Steamlit](https://streamlit.io/)
- Easy GUI in python (runs in browser)
- Has UI elements for LLM interaction ([Example](https://llm-examples.streamlit.app/?ref=streamlit-io-gallery-llms))

## Setup Tutorials (old/other)
- [Build and Deploy a LangChain-Powered Chat App with Docker and Streamlit](https://www.docker.com/blog/build-and-deploy-a-langchain-powered-chat-app-with-docker-and-streamlit/)
- [Self-hosting LangSmith with Docker](https://docs.smith.langchain.com/self_hosting/installation/docker)
- [Langchain + Docker + Neo4j + Ollama stack](https://github.com/docker/genai-stack)